{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Data Lake with Spark and S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql.functions import col, desc\n",
    "import os\n",
    "import configparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "\n",
    "config.read_file(open('dl.cfg'))\n",
    "\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"]= config['default']['AWS_ACCESS_KEY_ID']\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"]= config['default']['AWS_SECRET_ACCESS_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create spark session with hadoop-aws package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "configure = SparkConf().setAppName(\"app name\").setMaster(\"local\")\n",
    "sc = SparkContext(conf = configure)\n",
    "spark = SparkSession.builder\\\n",
    "                    .config('fs.s3a.access.key', os.environ['AWS_ACCESS_KEY_ID']) \\\n",
    "                    .config('fs.s3a.secret.key', os.environ['AWS_SECRET_ACCESS_KEY']) \\\n",
    "                    .appName(\"app name\")\\\n",
    "                     .config(\"spark.jars.packages\",\"org.apache.hadoop:hadoop-aws:2.7.3\")\\\n",
    "                     .getOrCreate()                   "
   ]
  },
  {
   "source": [
    "# Analysis"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data = \"data/output/\"\n",
    "song_df = spark.read\\\n",
    "        .format(\"parquet\")\\\n",
    "        .option(\"basePath\", os.path.join(output_data, \"songs/\"))\\\n",
    "        .load(os.path.join(output_data, \"songs/*/*/\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "root\n",
      " |-- song_id: string (nullable = true)\n",
      " |-- duration: double (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- artist_id: string (nullable = true)\n",
      "\n",
      "+------------------+---------+--------------------+----+------------------+\n",
      "|           song_id| duration|               title|year|         artist_id|\n",
      "+------------------+---------+--------------------+----+------------------+\n",
      "|SOAOIBZ12AB01815BE| 43.36281|I Hold Your Hand ...|2000|ARPBNLO1187FB3D52F|\n",
      "|SONYPOM12A8C13B2D7|186.48771|I Think My Wife I...|2005|ARDNS031187B9924F0|\n",
      "|SODREIN12A58A7F2E5|326.00771|A Whiter Shade Of...|   0|ARLTWXK1187FB5A3F8|\n",
      "+------------------+---------+--------------------+----+------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "song_df.printSchema()\n",
    "song_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data = \"data/output/\"\n",
    "artists_df = spark.read\\\n",
    "        .format(\"parquet\")\\\n",
    "        .option(\"basePath\", os.path.join(output_data, \"artists/\"))\\\n",
    "        .load(os.path.join(output_data, \"artists/*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "root\n",
      " |-- artist_id: string (nullable = true)\n",
      " |-- artist_latitude: double (nullable = true)\n",
      " |-- artist_longitude: double (nullable = true)\n",
      " |-- artist_location: string (nullable = true)\n",
      " |-- artist_name: string (nullable = true)\n",
      " |-- year: long (nullable = true)\n",
      " |-- num_songs: long (nullable = true)\n",
      "\n",
      "+------------------+---------------+----------------+-----------------+--------------------+----+---------+\n",
      "|         artist_id|artist_latitude|artist_longitude|  artist_location|         artist_name|year|num_songs|\n",
      "+------------------+---------------+----------------+-----------------+--------------------+----+---------+\n",
      "|ARDR4AC1187FB371A1|           null|            null|                 |Montserrat Caball...|   0|        1|\n",
      "|AREBBGV1187FB523D2|           null|            null|      Houston, TX|Mike Jones (Featu...|   0|        1|\n",
      "|ARMAC4T1187FB3FA4C|       40.82624|       -74.47995|Morris Plains, NJ|The Dillinger Esc...|2004|        1|\n",
      "+------------------+---------------+----------------+-----------------+--------------------+----+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "artists_df.printSchema()\n",
    "artists_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "root\n",
      " |-- start_time: timestamp (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      " |-- song_id: string (nullable = true)\n",
      " |-- artist_id: string (nullable = true)\n",
      " |-- session_id: long (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- user_agent: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      "\n",
      "+--------------------+-------+-----+-------+---------+----------+--------------------+--------------------+----+-----+\n",
      "|          start_time|user_id|level|song_id|artist_id|session_id|            location|          user_agent|year|month|\n",
      "+--------------------+-------+-----+-------+---------+----------+--------------------+--------------------+----+-----+\n",
      "|2018-11-14 22:30:...|     26| free|   null|     null|       583|San Jose-Sunnyval...|\"Mozilla/5.0 (X11...|2018|   11|\n",
      "|2018-11-14 22:41:...|     26| free|   null|     null|       583|San Jose-Sunnyval...|\"Mozilla/5.0 (X11...|2018|   11|\n",
      "|2018-11-14 22:45:...|     26| free|   null|     null|       583|San Jose-Sunnyval...|\"Mozilla/5.0 (X11...|2018|   11|\n",
      "+--------------------+-------+-----+-------+---------+----------+--------------------+--------------------+----+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output_data = \"data/output/\"\n",
    "songplays_df = spark.read\\\n",
    "        .format(\"parquet\")\\\n",
    "        .option(\"basePath\", os.path.join(output_data, \"songplays/\"))\\\n",
    "        .load(os.path.join(output_data, \"songplays/*\"))\n",
    "songplays_df.printSchema()\n",
    "songplays_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_df = song_df.alias(\"s\")\n",
    "artists_df = artists_df.alias(\"a\")\n",
    "songplays_df = songplays_df.alias(\"sp\")\n",
    "sparkify_table = songplays_df.join(\n",
    "        song_df, \n",
    "        songplays_df.song_id == song_df.song_id, \n",
    "        'left_outer')\\\n",
    "        .join(\n",
    "            artists_df,\n",
    "            artists_df.artist_id == artists_df.artist_id, 'left_outer')\n",
    "        #.select(col('s.year').alias('s_year'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "root\n",
      " |-- s_year: integer (nullable = true)\n",
      "\n",
      "+------+\n",
      "|s_year|\n",
      "+------+\n",
      "|  null|\n",
      "+------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sparkify_table.printSchema()\n",
    "sparkify_table.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------------------+\n|         artist_name|\n+--------------------+\n|Montserrat Caball...|\n|Mike Jones (Featu...|\n|The Dillinger Esc...|\n|            Tiny Tim|\n|          Tim Wilson|\n|   Sophie B. Hawkins|\n|         King Curtis|\n|         Lupe Fiasco|\n|Nick Ingman;Gavyn...|\n|         Willie Bobo|\n|    Billie Jo Spears|\n|Kenny G featuring...|\n|        SUE THOMPSON|\n|Jeff And Sheri Ea...|\n|Tweeterfriendly M...|\n|       Terry Callier|\n|        Jimmy Wakely|\n|        David Martin|\n|      Bombay Rockers|\n|           Tom Petty|\n+--------------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "songs_in_hour = sparkify_table.filter(col('sp.year') == 2018).select(col('a.artist_name'))\n",
    "songs_in_hour.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-------+-----+\n|user_id|count|\n+-------+-----+\n|     49|48919|\n|     80|47215|\n|     97|39547|\n|     15|32873|\n|     44|28187|\n|     29|24566|\n|     24|22791|\n|     73|20519|\n|     88|19170|\n|     36|17608|\n|     16|15833|\n|     95|15123|\n|     85|12709|\n|     30|12638|\n|     25|11999|\n|     58| 9940|\n|     42| 9940|\n|     26| 8094|\n|     82| 6177|\n|     72| 5112|\n+-------+-----+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "top_users = sparkify_table.groupby(col('sp.user_id')).count().orderBy(desc('count'))\n",
    "top_users.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "root\n |-- user_id: string (nullable = true)\n |-- first_name: string (nullable = true)\n |-- last_name: string (nullable = true)\n |-- gender: string (nullable = true)\n |-- level: string (nullable = true)\n\n+-------+----------+---------+------+-----+\n|user_id|first_name|last_name|gender|level|\n+-------+----------+---------+------+-----+\n|     88|  Mohammad|Rodriguez|     M| free|\n|     88|  Mohammad|Rodriguez|     M| paid|\n|     75|    Joseph|Gutierrez|     M| free|\n+-------+----------+---------+------+-----+\nonly showing top 3 rows\n\n"
     ]
    }
   ],
   "source": [
    "output_data = \"data/output/\"\n",
    "users_df = spark.read\\\n",
    "        .format(\"parquet\")\\\n",
    "        .option(\"basePath\", os.path.join(output_data, \"users/\"))\\\n",
    "        .load(os.path.join(output_data, \"users/*\"))\n",
    "users_df.printSchema()\n",
    "users_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_user_data = top_users.join(\n",
    "    users_df,\n",
    "    users_df.user_id == top_users.user_id,\n",
    "    'inner'\n",
    ").dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-------+-----+-------+----------+---------+------+-----+\n|user_id|count|user_id|first_name|last_name|gender|level|\n+-------+-----+-------+----------+---------+------+-----+\n|     49|48919|     49|     Chloe|   Cuevas|     F| free|\n|     49|48919|     49|     Chloe|   Cuevas|     F| paid|\n|     80|47215|     80|     Tegan|   Levine|     F| free|\n|     80|47215|     80|     Tegan|   Levine|     F| paid|\n|     97|39547|     97|      Kate|  Harrell|     F| paid|\n|     15|32873|     15|      Lily|     Koch|     F| paid|\n|     15|32873|     15|      Lily|     Koch|     F| free|\n|     44|28187|     44|    Aleena|    Kirby|     F| paid|\n|     29|24566|     29|Jacqueline|    Lynch|     F| free|\n|     29|24566|     29|Jacqueline|    Lynch|     F| paid|\n|     24|22791|     24|     Layla|  Griffin|     F| paid|\n|     73|20519|     73|     Jacob|    Klein|     M| paid|\n|     88|19170|     88|  Mohammad|Rodriguez|     M| free|\n|     88|19170|     88|  Mohammad|Rodriguez|     M| paid|\n|     36|17608|     36|   Matthew|    Jones|     M| paid|\n|     36|17608|     36|   Matthew|    Jones|     M| free|\n|     16|15833|     16|     Rylan|   George|     M| free|\n|     16|15833|     16|     Rylan|   George|     M| paid|\n|     95|15123|     95|      Sara|  Johnson|     F| paid|\n|     85|12709|     85|   Kinsley|    Young|     F| free|\n+-------+-----+-------+----------+---------+------+-----+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "top_user_data.orderBy(desc('count')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.13 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "interpreter": {
   "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}